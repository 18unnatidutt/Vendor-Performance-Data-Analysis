{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2b5200",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import urllib.parse\n",
    "import os\n",
    "from sqlalchemy import create_engine\n",
    "import logging\n",
    "import time\n",
    "import psycopg2\n",
    "logging.basicConfig(\n",
    "    filename=\"logs/ingestion.log\",\n",
    "    level=logging.DEBUG,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    filemode=\"a\"\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "336cfdfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def load_raw_data():\n",
    "#   for file in os.listdir('data'):\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a424e6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".ipynb_checkpoints\n",
      "begin_inventory.csv\n",
      "end_inventory.csv\n",
      "purchases.csv\n",
      "purchase_prices.csv\n",
      "sales.csv\n",
      "vendor_invoice.csv\n"
     ]
    }
   ],
   "source": [
    "for file in os.listdir('data'):\n",
    "    print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6d48ae3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingesting begin_inventory.csv ...\n",
      "begin_inventory.csv ingestion completed!\n",
      "Ingesting end_inventory.csv ...\n",
      "end_inventory.csv ingestion completed!\n",
      "Ingesting purchases.csv ...\n",
      "purchases.csv ingestion completed!\n",
      "Ingesting purchase_prices.csv ...\n",
      "purchase_prices.csv ingestion completed!\n",
      "Ingesting sales.csv ...\n",
      "sales.csv ingestion completed!\n",
      "Ingesting vendor_invoice.csv ...\n",
      "vendor_invoice.csv ingestion completed!\n",
      "All files ingested successfully!\n"
     ]
    }
   ],
   "source": [
    "DB_HOST = 'localhost'      # e.g., 'localhost' or server IP\n",
    "DB_PORT = '5432'                   # default PostgreSQL port\n",
    "DB_NAME = 'vendor_inventory_db'      # your database name\n",
    "DB_USER = 'postgres'\n",
    "DB_PASS = 'newpassword'\n",
    "\n",
    "# Create SQLAlchemy engine\n",
    "engine = create_engine(f'postgresql+psycopg2://{DB_USER}:{DB_PASS}@{DB_HOST}:{DB_PORT}/{DB_NAME}')\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: CSV file path\n",
    "csv_file = 'data'\n",
    "\n",
    "# Step 5: Define chunk size (number of rows per batch)\n",
    "chunk_size = 50000  # adjust based on your RAM\n",
    "data_folder='data'\n",
    "# Step 6: Ingest CSV in chunks\n",
    "for file_name in os.listdir(data_folder):\n",
    "    if file_name.endswith('.csv'):\n",
    "        file_path = os.path.join(data_folder, file_name)\n",
    "        print(f\"Ingesting {file_name} ...\")\n",
    "        \n",
    "        for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "            # Table name can be file name without extension\n",
    "            table_name = os.path.splitext(file_name)[0]\n",
    "            chunk.to_sql(table_name, engine, if_exists='replace', index=False)\n",
    "        \n",
    "        print(f\"{file_name} ingestion completed!\")\n",
    "\n",
    "print(\"All files ingested successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785f97c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
